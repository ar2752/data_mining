{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2145fc-e878-475e-8d49-375ea15f5155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are databases you can explore....\n",
      "1) Shop & Stop\n",
      "2) Walgreens\n",
      "3) Kroger\n",
      "4) Walmart\n",
      "5) CVS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick a database by number:  3\n",
      "Enter minimum support as a percentage ranging 1 - 100 % (e.g., 2% -> 2):  36\n",
      "Enter minimum confidence as a percentage ranging 1 - 100 % (e.g., 2% -> 2):  23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations, chain\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules\n",
    "import time\n",
    "\n",
    "print(\"Here are databases you can explore....\")\n",
    "print(\"1) Stop & Shop\")\n",
    "print(\"2) Walgreens\")\n",
    "print(\"3) Kroger\")\n",
    "print(\"4) Walmart\")\n",
    "print(\"5) CVS\")\n",
    "      \n",
    "\n",
    "while True:\n",
    "    \n",
    "    try:\n",
    "        database = int(input(\"Pick a database by number: \"))\n",
    "        if 0 < database <= 5 :\n",
    "            if database == 1:\n",
    "                print(\"Stop & Shop Chosen!\")\n",
    "            if database == 2:\n",
    "                print(\"Walgreens Chosen!\")\n",
    "            if database == 3:\n",
    "                print(\"Kroger Chosen!\")\n",
    "            if database == 4:\n",
    "                print(\"Walmart Chosen!\")\n",
    "            if database == 5:\n",
    "                print(\"CVS Chosen!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Error: Database number must be between 1 and 5.\")\n",
    "    except ValueError:\n",
    "        print(\"Error: Please enter a valid number.\")\n",
    "\n",
    "\n",
    "\n",
    "mapping = {1:'db_1.csv',2:'db_2.csv',3:'db_3.csv',4:'db_4.csv',5:'db_5.csv'}\n",
    "file_path = mapping[database]\n",
    "while True:\n",
    "    min_support_input = input(\"Enter minimum support as a percentage ranging 1 - 100 % (e.g., 2% -> 2): \")\n",
    "    try:\n",
    "        min_support = float(min_support_input) / 100\n",
    "        if 0 < min_support <= 1:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Error: Minimum support must be between 1 and 100.\")\n",
    "    except ValueError:\n",
    "        print(\"Error: Please enter a valid number.\")\n",
    "\n",
    "    # Prompt for minimum confidence with validation\n",
    "while True:\n",
    "    min_confidence_input = input(\"Enter minimum confidence as a percentage ranging 1 - 100 % (e.g., 2% -> 2): \")\n",
    "    try:\n",
    "        min_confidence = float(min_confidence_input) / 100\n",
    "        if 0 < min_confidence <= 1:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Error: Minimum confidence must be between 1 and 100.\")\n",
    "    except ValueError:\n",
    "        print(\"Error: Please enter a valid number.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdcd1cdb-1731-4e4f-a5b6-dc1aef4deb59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_transactions_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    transactions = df['Items'].apply(lambda x: set(x.split(', '))).tolist()\n",
    "    return transactions\n",
    "transactions = load_transactions_from_csv(file_path)\n",
    "transactions_list = [list(t) for t in transactions] \n",
    "print(\"Transactions from this database \\n\")\n",
    "print(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1000d523-19df-4fa0-824e-e5f07482dd28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_frequent_itemsets_bruteforce(transactions, min_support):\n",
    "    all_items = set(item for transaction in transactions for item in transaction)\n",
    "    total_transactions = len(transactions)\n",
    "    max_itemset_size = max([len(transaction) for transaction in transactions])\n",
    "    def calc_support(itemset):\n",
    "        count = sum(1 for trans in transactions if itemset.issubset(trans))\n",
    "        return count / total_transactions\n",
    "    \n",
    "    current_itemsets = [frozenset([item]) for item in all_items]\n",
    "    frequent_itemsets = []\n",
    "    k = 1\n",
    "    \n",
    "    while current_itemsets:\n",
    "        new_frequent_itemsets = [itemset for itemset in current_itemsets if calc_support(itemset) >= min_support]\n",
    "        if not new_frequent_itemsets:\n",
    "            break\n",
    "        frequent_itemsets.extend(new_frequent_itemsets)\n",
    "        if k < max_itemset_size:\n",
    "            next_level_itemsets = set()\n",
    "            for i in range(len(new_frequent_itemsets)):\n",
    "                for j in range(i + 1, len(new_frequent_itemsets)):\n",
    "                    union_set = new_frequent_itemsets[i].union(new_frequent_itemsets[j])\n",
    "                    if len(union_set) == k + 1:\n",
    "                        next_level_itemsets.add(union_set)\n",
    "            current_itemsets = list(next_level_itemsets)\n",
    "        else:\n",
    "            break\n",
    "        k += 1\n",
    "    \n",
    "    return frequent_itemsets\n",
    "\n",
    "def generate_rules(frequent_itemsets, transactions, min_confidence):\n",
    "    rules = []\n",
    "\n",
    "    def calc_support(itemset):\n",
    "        return sum(1 for trans in transactions if itemset.issubset(trans)) / len(transactions)\n",
    "\n",
    "    def calc_confidence(antecedent, consequent):\n",
    "        antecedent_consequent = antecedent.union(consequent)\n",
    "        return calc_support(antecedent_consequent) / calc_support(antecedent)\n",
    "\n",
    "    for itemset in frequent_itemsets:\n",
    "        for antecedent in chain.from_iterable(combinations(itemset, r) for r in range(1, len(itemset))):\n",
    "            antecedent_set = frozenset(antecedent)\n",
    "            consequent_set = itemset - antecedent_set\n",
    "            confidence = calc_confidence(antecedent_set, consequent_set)\n",
    "            if confidence >= min_confidence:\n",
    "                rules.append((antecedent_set, consequent_set, calc_support(itemset), confidence))\n",
    "    return rules\n",
    "\n",
    "def run_algorithm(transactions, min_support, min_confidence, algorithm='apriori'):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    start_time = time.time()\n",
    "    if algorithm == 'apriori':\n",
    "        frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    else:\n",
    "        frequent_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    print(f\"\\n{algorithm.capitalize()} Execution Time: {time.time() - start_time} seconds\")\n",
    "    return rules\n",
    "\n",
    "def print_rules(rules, title):\n",
    "    print(f\"\\n{title}:\")\n",
    "    for rule in rules:\n",
    "        antecedent, consequent, support, confidence = rule\n",
    "        # Convert frozensets to sorted lists and then to strings for nicer printing\n",
    "        antecedent_str = ', '.join(sorted(antecedent))\n",
    "        consequent_str = ', '.join(sorted(consequent))\n",
    "        print(f\"Rule: {{{antecedent_str}}} => {{{consequent_str}}}, Support: {support:.2f}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "def format_mlxtend_rules(rules_df):\n",
    "    formatted_rules = []\n",
    "    for _, row in rules_df.iterrows():\n",
    "        antecedent = frozenset(row['antecedents'])\n",
    "        consequent = frozenset(row['consequents'])\n",
    "        support = row['support']\n",
    "        confidence = row['confidence']\n",
    "        formatted_rules.append((antecedent, consequent, support, confidence))\n",
    "    return formatted_rules\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rules_to_set(rules):\n",
    "    \"\"\"Convert rules into a set of immutable elements for comparison.\"\"\"\n",
    "    return set(\n",
    "        (frozenset(antecedent), frozenset(consequent), round(support, 4), round(confidence, 4))\n",
    "        for antecedent, consequent, support, confidence in rules\n",
    "    )\n",
    "\n",
    "def validate_rules_equivalence(brute_force_rules, mlxtend_rules_df):\n",
    "    \"\"\"\n",
    "    Validates that the sets of rules from the Brute Force method and the MLxtend method\n",
    "    (Apriori or FP-Growth) are exactly equivalent, without considering the order of the\n",
    "    rules.\n",
    "\n",
    "    :param brute_force_rules: Rules generated by the brute force method.\n",
    "    :param mlxtend_rules_df: Rules generated by the MLxtend method (DataFrame format).\n",
    "    :return: True if the sets of rules are exactly equivalent, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert brute_force_rules to set for easy comparison\n",
    "    brute_force_set = rules_to_set(brute_force_rules)\n",
    "\n",
    "    # Convert mlxtend_rules_df DataFrame to a set of tuples\n",
    "    mlxtend_set = set()\n",
    "    for _, row in mlxtend_rules_df.iterrows():\n",
    "        antecedent = frozenset(row['antecedents'])\n",
    "        consequent = frozenset(row['consequents'])\n",
    "        support = round(row['support'], 4)  # Assuming support is a column in the DataFrame\n",
    "        confidence = round(row['confidence'], 4)  # Assuming confidence is a column\n",
    "        mlxtend_set.add((antecedent, consequent, support, confidence))\n",
    "\n",
    "    # Directly compare the sets\n",
    "    return brute_force_set == mlxtend_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b50c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70427e9-d701-48b2-b039-2e9fa9a1b8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset({'Kraft Macaroni & Cheese'}), frozenset({'Haagen-Dazs Ice Cream'}), frozenset({'Green Giant Frozen Vegetables'}), frozenset({\"Campbell's Soup\"}), frozenset({'Chiquita Bananas'}), frozenset({'Kraft Macaroni & Cheese', 'Haagen-Dazs Ice Cream'}), frozenset({'Kraft Macaroni & Cheese', \"Campbell's Soup\"})] Frequwnt itemsets from Brute-Force\n",
      "\n",
      "Brute Force Execution Time: 0.0007586479187011719 seconds\n",
      "\n",
      "Brute Force Rules:\n",
      "Rule: {Kraft Macaroni & Cheese} => {Haagen-Dazs Ice Cream}, Support: 0.38, Confidence: 0.53\n",
      "Rule: {Haagen-Dazs Ice Cream} => {Kraft Macaroni & Cheese}, Support: 0.38, Confidence: 0.80\n",
      "Rule: {Kraft Macaroni & Cheese} => {Campbell's Soup}, Support: 0.43, Confidence: 0.60\n",
      "Rule: {Campbell's Soup} => {Kraft Macaroni & Cheese}, Support: 0.43, Confidence: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Execute Brute Force Method\n",
    "start_time = time.time()\n",
    "frequent_itemsets = find_frequent_itemsets_bruteforce(transactions, min_support)\n",
    "tuple_list = [tuple(fs) for fs in frequent_itemsets]\n",
    "print(\"Frequent item sets from Brute Force Method \\n\")\n",
    "print(tuple_list)\n",
    "brute_force_rules = generate_rules(frequent_itemsets, transactions, min_confidence)\n",
    "end_time = time.time()\n",
    "print(f\"\\nBrute Force Execution Time: {end_time - start_time} seconds\")\n",
    "print_rules(brute_force_rules, \"Brute Force Rules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d573e2a0-7bde-495a-988f-cf7f3d8fe1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Apriori Execution Time: 0.008752107620239258 seconds\n",
      "Apriori Execution Time: 0.010643959045410156 seconds\n",
      "\n",
      "Apriori Rules:\n",
      "Rule: {Kraft Macaroni & Cheese} => {Campbell's Soup}, Support: 0.43, Confidence: 0.60\n",
      "Rule: {Campbell's Soup} => {Kraft Macaroni & Cheese}, Support: 0.43, Confidence: 0.64\n",
      "Rule: {Haagen-Dazs Ice Cream} => {Kraft Macaroni & Cheese}, Support: 0.38, Confidence: 0.80\n",
      "Rule: {Kraft Macaroni & Cheese} => {Haagen-Dazs Ice Cream}, Support: 0.38, Confidence: 0.53\n"
     ]
    }
   ],
   "source": [
    "  # Execute Apriori\n",
    "start_time = time.time()\n",
    "apriori_rules_df = run_algorithm(transactions_list, min_support, min_confidence, 'apriori')\n",
    "apriori_rules = format_mlxtend_rules(apriori_rules_df)\n",
    "end_time = time.time()\n",
    "print(f\"Apriori Execution Time: {end_time - start_time} seconds\")\n",
    "print_rules(apriori_rules, \"Apriori Rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6bd1477-84f5-468b-b6e8-605bf2e11d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fpgrowth Execution Time: 0.010232686996459961 seconds\n",
      "FP-Growth Execution Time: 0.01645803451538086 seconds\n",
      "\n",
      "FP-Growth Rules:\n",
      "Rule: {Haagen-Dazs Ice Cream} => {Kraft Macaroni & Cheese}, Support: 0.38, Confidence: 0.80\n",
      "Rule: {Kraft Macaroni & Cheese} => {Campbell's Soup}, Support: 0.43, Confidence: 0.60\n",
      "Rule: {Campbell's Soup} => {Kraft Macaroni & Cheese}, Support: 0.43, Confidence: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Execute FP-Growth\n",
    "start_time = time.time()\n",
    "fp_growth_rules_df = run_algorithm(transactions_list, min_support, min_confidence, 'fpgrowth')\n",
    "fp_growth_rules = format_mlxtend_rules(fp_growth_rules_df)\n",
    "end_time = time.time()\n",
    "print(f\"FP-Growth Execution Time: {end_time - start_time} seconds\")\n",
    "print_rules(fp_growth_rules, \"FP-Growth Rules\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88eb1d56-755c-4643-b41c-8a83856a5166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute Force and Apriori rules are equivalent: True\n",
      "Brute Force and FP-Growth rules are equivalent: True\n"
     ]
    }
   ],
   "source": [
    "are_apriori_rules_equivalent = validate_rules_equivalence(brute_force_rules, apriori_rules_df)\n",
    "print(f\"Brute Force and Apriori rules are equivalent: {are_apriori_rules_equivalent}\")\n",
    "\n",
    "# Validate equivalence of Brute Force and FP-Growth rules\n",
    "are_fp_growth_rules_equivalent = validate_rules_equivalence(brute_force_rules, fp_growth_rules_df)\n",
    "print(f\"Brute Force and FP-Growth rules are equivalent: {are_fp_growth_rules_equivalent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0289ed3-d0b4-4bf6-89bf-53da17826056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7500c3e1c7c786e4ba1e4b4eb7588219b4e35d5153674f92eb3a82672b534f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
